{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cardiac",
      "provenance": [],
      "authorship_tag": "ABX9TyNq8MX1NI8LzFv7ozgZcpUv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0994b4b968e743d6a99692c304166f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_315e4b9612bf4da381db1f596e01d2b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07f23b6935ee4bcdbd0b1ff931fb88b9",
              "IPY_MODEL_49e61685aefe4879bdef50ea91cdc5da"
            ]
          }
        },
        "315e4b9612bf4da381db1f596e01d2b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07f23b6935ee4bcdbd0b1ff931fb88b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efdee01e9f0d4bceabcacf5aeeadff27",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17a647e2ce514a3395bc9af5bfe5786b"
          }
        },
        "49e61685aefe4879bdef50ea91cdc5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a9feb73afb64b9a9fb2616078bca737",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:03&lt;00:00, 144MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7a2523b5b9e4af28068fe7af5a910c7"
          }
        },
        "efdee01e9f0d4bceabcacf5aeeadff27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17a647e2ce514a3395bc9af5bfe5786b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a9feb73afb64b9a9fb2616078bca737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7a2523b5b9e4af28068fe7af5a910c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsurapol/Python-Programming/blob/master/Cardiac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0994b4b968e743d6a99692c304166f4a",
            "315e4b9612bf4da381db1f596e01d2b5",
            "07f23b6935ee4bcdbd0b1ff931fb88b9",
            "49e61685aefe4879bdef50ea91cdc5da",
            "efdee01e9f0d4bceabcacf5aeeadff27",
            "17a647e2ce514a3395bc9af5bfe5786b",
            "7a9feb73afb64b9a9fb2616078bca737",
            "f7a2523b5b9e4af28068fe7af5a910c7"
          ]
        },
        "id": "g2X66_DvqXBF",
        "outputId": "a9ee29ae-7903-4bc8-bac0-ac6b514438c1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms,models\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "class SUP(nn.Module):\n",
        "    def __init__(self, inchannel,outchannel):\n",
        "        super(SUP, self).__init__()\n",
        "        #self.feature=feature\n",
        "        self.conv1 = nn.Conv2d(inchannel, 1, kernel_size=(1, 1), stride=1, padding=0)\n",
        "        self.softmax=nn.Softmax(dim=2)\n",
        "        self.conv2 = nn.Conv2d(inchannel, outchannel, kernel_size=(1, 1), stride=1, padding=0)\n",
        "        self.ln=nn.LayerNorm([outchannel,1,1])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(outchannel, outchannel, kernel_size=(1, 1), stride=1, padding=0)\n",
        "\n",
        "    def spatial_pool(self,x):\n",
        "        batch,channel,height,width=x.size()\n",
        "\n",
        "        input_x=x\n",
        "        #print(input_x.shape)\n",
        "        input_x=input_x.view(batch,channel,height*width)\n",
        "        #print(input_x.shape)\n",
        "        input_x=input_x.unsqueeze(1)\n",
        "        #print(x.shape)\n",
        "        context_mask=self.conv1(x)\n",
        "        #print(context_mask.shape)\n",
        "        context_mask1=context_mask.view(batch,1,height*width)\n",
        "        context_mask2=self.softmax(context_mask1)\n",
        "        context_mask3=context_mask2.unsqueeze(-1)\n",
        "        context=torch.matmul(input_x,context_mask3)\n",
        "        context=context.view(batch,channel,1,1)\n",
        "        return context\n",
        "    def forward(self, high_feature):\n",
        "        #high_feature=nn.functional.interpolate(high_feature,(self.feature.shape[2],self.feature.shape[3]),mode='bilinear',align_corners=False)\n",
        "        context_1=self.spatial_pool(high_feature)\n",
        "        context_2=self.conv2(context_1)\n",
        "        context_3=self.ln(context_2)\n",
        "        context_4=self.relu(context_3)\n",
        "        context_5=self.conv3(context_4)\n",
        "        return context_5\n",
        "\n",
        "class ECA(nn.Module):\n",
        "    def __init__(self, gamma=2,k_size=1):\n",
        "        super(ECA, self).__init__()\n",
        "        self.avg_pool=nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv=nn.Conv1d(1,1,kernel_size=k_size,padding=(k_size-1)//2,bias=False)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        N,C,H,W=x.size()\n",
        "        y=self.avg_pool(x)\n",
        "        y=self.conv(y.squeeze(-1).transpose(-1,-2)).transpose(-1,-2).unsqueeze(-1)\n",
        "        y=self.sigmoid(y)\n",
        "        return x*y.expand_as(x)\n",
        "\n",
        "\n",
        "class SS(nn.Module):\n",
        "    def __init__(self, inchannel,outchannel):\n",
        "        super(SS, self).__init__()\n",
        "        self.k_size=3\n",
        "        self.conv1=nn.Conv2d(inchannel,outchannel,kernel_size=(7,7),stride=2,padding=3)\n",
        "        self.relu=nn.ReLU(inplace=True)\n",
        "        self.conv2=nn.Conv2d(outchannel,outchannel,kernel_size=(3,3),stride=1,padding=1)\n",
        "        self.eca=ECA(outchannel,k_size=3)\n",
        "    def forward(self, x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.conv2(x)\n",
        "        s=self.eca(x)\n",
        "        return s\n",
        "\n",
        "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
        "    '''\n",
        "    return a bilinear filter tensor\n",
        "    '''\n",
        "    factor = (kernel_size + 1) // 2\n",
        "    if kernel_size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:kernel_size, :kernel_size]\n",
        "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
        "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype='float32')\n",
        "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
        "    return torch.from_numpy(weight)\n",
        "\n",
        "\n",
        "class mynet(nn.Module):\n",
        "    def __init__(self, num_category):\n",
        "        super(mynet, self).__init__()\n",
        "\n",
        "        model_ft = models.vgg16(pretrained=True)\n",
        "        features = list(model_ft.features.children())\n",
        "        conv1 = nn.Conv2d(3, 64, 3, 1, 100)\n",
        "        conv1.weight.data = features[0].weight.data\n",
        "        conv1.bias.data = features[0].bias.data\n",
        "        features[0] = conv1\n",
        "        features[4] = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        features[9] = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        features[16] = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        features[23] = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        features[30] = nn.MaxPool2d(2, 2, ceil_mode=True)\n",
        "        self.conv=nn.Sequential(*features[:2])\n",
        "        self.stage1 = nn.Sequential(*features[2:5])  # ???\n",
        "        self.ss1=SS(64,64)\n",
        "        self.stage2=nn.Sequential(*features[5:10])\n",
        "        self.ss2 = SS(64, 128)\n",
        "\n",
        "        self.stage3=nn.Sequential(*features[10:17])\n",
        "        self.ss3 = SS(128, 256)\n",
        "        self.stage4 = nn.Sequential(*features[17:24])  # ???\n",
        "        self.ss4 = SS(256, 512)\n",
        "        self.stage5= nn.Sequential(*features[24:])  # ???\n",
        "        self.ss5 = SS(512, 512)\n",
        "\n",
        "        # fc6, fc7a\n",
        "        fc = list(model_ft.classifier.children())\n",
        "        fc6 = nn.Conv2d(512, 1024, 7)\n",
        "        fc7 = nn.Conv2d(1024, 1024, 1)\n",
        "        fc[0] = fc6\n",
        "        fc[3] = fc7\n",
        "        self.fc = nn.Sequential(*fc[:6])\n",
        "\n",
        "        self.scores1 = nn.Conv2d(1024, num_category*4, 1)  #\n",
        "        self.scores2 = nn.Conv2d(512, num_category, 1)\n",
        "        self.scores3 = nn.Conv2d(256, num_category, 1)\n",
        "        self.scores4 = nn.Conv2d(128, num_category, 1)\n",
        "        self.scores5 = nn.Conv2d(64, num_category, 1)\n",
        "\n",
        "        self.sup1=SUP(1024,512)\n",
        "        self.sup2=SUP(512,256)\n",
        "        self.sup3=SUP(256,128)\n",
        "        self.sup4=SUP(128,64)\n",
        "\n",
        "\n",
        "        for layer in [self.scores1, self.scores2, self.scores3,self.scores4,self.scores5]:\n",
        "            nn.init.kaiming_normal_(layer.weight, a=1)\n",
        "            nn.init.constant_(layer.bias, 0)\n",
        "        self.upsample_32x = nn.ConvTranspose2d(num_category, num_category, 4, 2, bias=False)\n",
        "        self.upsample_32x.weight.data = bilinear_kernel(num_category, num_category, 4)\n",
        "\n",
        "        self.upsample_16x = nn.ConvTranspose2d(num_category, num_category, 4, 2, bias=False)\n",
        "        self.upsample_16x.weight.data = bilinear_kernel(num_category, num_category, 4)\n",
        "\n",
        "        self.upsample_8x = nn.ConvTranspose2d(num_category, num_category, 4, 2, bias=False)\n",
        "        self.upsample_8x.weight.data = bilinear_kernel(num_category, num_category, 4)  # ????? kernel\n",
        "\n",
        "        self.upsample_4x = nn.ConvTranspose2d(num_category, num_category, 4, 2, bias=False)\n",
        "        self.upsample_4x.weight.data = bilinear_kernel(num_category, num_category, 4)  # ????? kernel\n",
        "\n",
        "        self.upsample_2x = nn.ConvTranspose2d(num_category, num_category, 4, 2, bias=False)\n",
        "        self.upsample_2x.weight.data = bilinear_kernel(num_category, num_category, 4)  # ????? kernel\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0=self.conv(x)\n",
        "        h1 = self.stage1(h0)\n",
        "        a1=self.ss1(h0)\n",
        "\n",
        "\n",
        "        g1 = h1+a1  # 1/2\n",
        "\n",
        "        h2 = self.stage2(g1)\n",
        "        a2 = self.ss2(g1)\n",
        "\n",
        "        g2 = h2+a2  # 1/4\n",
        "\n",
        "        h3 = self.stage3(g2)\n",
        "        a3 = self.ss3(g2)\n",
        "\n",
        "\n",
        "        g3 = h3+a3  # 1/8\n",
        "\n",
        "        h4 = self.stage4(g3)\n",
        "        a4 = self.ss4(g3)\n",
        "\n",
        "        g4=h4+a4 #1/16\n",
        "\n",
        "        h5= self.stage5(g4)\n",
        "        a5 = self.ss5(g4)\n",
        "        g5=h5+a5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        h = self.fc(g5)\n",
        "\n",
        "        s5 = h# 1/32\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        s5 = self.scores1(s5)\n",
        "        up = nn.PixelShuffle(2)\n",
        "        s5 = up(s5)\n",
        "\n",
        "        high_feature1 = nn.functional.interpolate(h, (g4.shape[2], g4.shape[3]), mode='bilinear', align_corners=False)\n",
        "        high_feature1 = self.sup1(high_feature1)\n",
        "        s4=high_feature1+g4\n",
        "        s4 = self.scores2(s4 * 1e-2)\n",
        "        s4 = s4[:, :, 5:5 + s5.size()[2], 5:5 + s5.size()[3]].contiguous()\n",
        "        s4 = s4 + s5\n",
        "\n",
        "\n",
        "        s4 = self.upsample_4x(s4)\n",
        "        high_feature2 = nn.functional.interpolate(g4, (g3.shape[2], g3.shape[3]), mode='bilinear', align_corners=False)\n",
        "        high_feature2 = self.sup2(high_feature2)\n",
        "        s3 = high_feature2 + g3\n",
        "        s3 = self.scores3(s3 * 1e-3)\n",
        "        s3 = s3[:, :, 9:9 + s4.size()[2], 9:9 + s4.size()[3]].contiguous()\n",
        "        s3 = s3 + s4\n",
        "\n",
        "        s3 = self.upsample_8x(s3)\n",
        "        high_feature3 = nn.functional.interpolate(g3, (g2.shape[2], g2.shape[3]), mode='bilinear', align_corners=False)\n",
        "        high_feature3 = self.sup3(high_feature3)\n",
        "        s2 = high_feature3 + g2\n",
        "        s2 = self.scores4(s2 * 1e-3)\n",
        "        s2 = s2[:, :, 17:17 + s3.size()[2], 17:17 + s3.size()[3]].contiguous()\n",
        "        s2=s2+s3\n",
        "\n",
        "        s2= self.upsample_16x(s2)\n",
        "        high_feature4 = nn.functional.interpolate(g2, (g1.shape[2], g1.shape[3]), mode='bilinear', align_corners=False)\n",
        "        high_feature4 = self.sup4(high_feature4)\n",
        "        s1 = high_feature4 + g1\n",
        "        s1 = self.scores5(s1 * 1e-4)\n",
        "        s1 = s1[:, :, 24:24 + s2.size()[2], 24:24 + s2.size()[3]].contiguous()\n",
        "        s1 = s1+ s2\n",
        "\n",
        "        s = self.upsample_32x(s1)\n",
        "        s = s[:, :, 31:31 + x.size()[2], 31:31 + x.size()[3]].contiguous()\n",
        "\n",
        "        return s\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    print(mynet(3))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0994b4b968e743d6a99692c304166f4a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "mynet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (stage1): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (ss1): SS(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (eca): ECA(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (stage2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (ss2): SS(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (eca): ECA(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (stage3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (ss3): SS(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (eca): ECA(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (stage4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (ss4): SS(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (eca): ECA(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (stage5): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  )\n",
            "  (ss5): SS(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (eca): ECA(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "      (sigmoid): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Conv2d(512, 1024, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (scores1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (scores2): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (scores3): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (scores4): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (scores5): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (sup1): SUP(\n",
            "    (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (softmax): Softmax(dim=2)\n",
            "    (conv2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (ln): LayerNorm((512, 1, 1), eps=1e-05, elementwise_affine=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (sup2): SUP(\n",
            "    (conv1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (softmax): Softmax(dim=2)\n",
            "    (conv2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (ln): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (sup3): SUP(\n",
            "    (conv1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (softmax): Softmax(dim=2)\n",
            "    (conv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (ln): LayerNorm((128, 1, 1), eps=1e-05, elementwise_affine=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (sup4): SUP(\n",
            "    (conv1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (softmax): Softmax(dim=2)\n",
            "    (conv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (ln): LayerNorm((64, 1, 1), eps=1e-05, elementwise_affine=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (upsample_32x): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "  (upsample_16x): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "  (upsample_8x): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "  (upsample_4x): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "  (upsample_2x): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "nwe5mayxref6",
        "outputId": "d539b33f-7014-4978-d65f-d67dbaeee1f9"
      },
      "source": [
        "from __future__ import print_function\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "import os.path as osp\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from skimage import io\n",
        "import glob\n",
        "from skimage import segmentation as seg\n",
        "\n",
        "\n",
        "datadir = '/home/guolibao/cardiac'\n",
        "voc_root = os.path.join(datadir, 'cardiac-4ch')\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
        "if torch.cuda.is_available():\n",
        "    device=torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "def read_images(root_dir, train):\n",
        "    txt_fname = root_dir + '/dic/' + ('train.txt' if train else 'val_ll.txt')\n",
        "    with open(txt_fname, 'r')as f:\n",
        "        images = f.read().split()\n",
        "\n",
        "    if train:\n",
        "        data_list = [os.path.join(root_dir, 'train', i) for i in images]\n",
        "\n",
        "        label_list = [os.path.join(root_dir, 'train_labels', i) for i in images]\n",
        "    else:\n",
        "        data_list = [os.path.join(root_dir, 'val', i) for i in images]\n",
        "        label_list = [os.path.join(root_dir, 'val_ma_labels', i) for i in images]\n",
        "    return data_list,label_list\n",
        "\n",
        "class Cardiac(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, root_dir=voc_root, train=True, trsf=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.trsf = trsf\n",
        "        self.data_list, self.label_list = read_images(root_dir, train)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data_list[idx], self.label_list[idx]\n",
        "        image, label = Image.open(image).convert('RGB'), Image.open(label)\n",
        "        image = transforms.Resize((512, 512), interpolation=Image.BILINEAR)(image)\n",
        "        label = transforms.Resize((512, 512), interpolation=Image.BILINEAR)(label)\n",
        "        sample = {'image': image, 'label': label}\n",
        "        if self.trsf:\n",
        "            sample = self.trsf(sample)\n",
        "        return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        image = transforms.ToTensor()(image)\n",
        "        label = torch.from_numpy(np.array(label, dtype='int'))\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    def __init__(self, mean=[0., 0., 0.], std=[1., 1., 1.]):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        image = transforms.Normalize(self.mean, self.std)(image)\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "\n",
        "def main():\n",
        "    transforms_train = transforms.Compose([  # transforms.Resize(448),\n",
        "        ToTensor(),\n",
        "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    transforms_val = transforms.Compose([  # transforms.Resize(448),\n",
        "        ToTensor(),\n",
        "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    voc_data = {\n",
        "                'val': Cardiac(root_dir=voc_root, train=False,\n",
        "                                  trsf=transforms_val)}\n",
        "\n",
        "\n",
        "\n",
        "    myfcn_ma = torch.load('/home/guolibao/PycharmProjects/fcn/model_ma/bisenet_ma55.pkl')\n",
        "\n",
        "\n",
        "\n",
        "    myfcn_ma.eval()  # Set model to evaluate mode\n",
        "    myfcn_ma.cuda()\n",
        "    colormap = [[0, 0, 0], [128, 0, 0]]\n",
        "    cm = np.array(colormap, dtype='uint8')\n",
        "    txt_fname = '/home/guolibao/cardiac/cardiac-4ch/dic/val.txt'\n",
        "    with open(txt_fname, 'r')as f:\n",
        "        images = f.read().split()\n",
        "    imgs = [os.path.join(datadir, 'cardiac/val_ma_labels', i) for i in images]\n",
        "    for i, img in enumerate(imgs):\n",
        "        val_sample = voc_data['val'][i]\n",
        "        val_image = val_sample['image'].cuda()\n",
        "        val_label = val_sample['label']\n",
        "        val_output = myfcn_ma(val_image.unsqueeze(0))\n",
        "        val_pred = val_output.max(dim=1)[1].squeeze(0).data.cpu().numpy()\n",
        "        val_label = val_label.long().data.numpy()\n",
        "        val_image = val_image.squeeze().data.cpu().numpy().transpose((1, 2, 0))\n",
        "        val_image = val_image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
        "        val_image *= 255\n",
        "        val_image = val_image.astype(np.uint8)\n",
        "        val_pred_tian = cm[val_pred]\n",
        "        val_pred_bin=seg.mark_boundaries(val_image, val_label, color=(128, 0, 0))\n",
        "        val_pred_bin=seg.mark_boundaries(val_pred_bin, val_pred, color=(0, 128, 0))\n",
        "\n",
        "        plt.imsave(osp.join('/home/guolibao/cardiac/pred_test/bisenet_ma', img.split('/')[-1]), val_pred_tian)\n",
        "        plt.imsave(osp.join('/home/guolibao/cardiac/pred_test/bisenet_ma_bin', img.split('/')[-1]), val_pred_bin)\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cb4631c274a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-cb4631c274a9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     voc_data = {\n\u001b[1;32m     95\u001b[0m                 'val': Cardiac(root_dir=voc_root, train=False,\n\u001b[0;32m---> 96\u001b[0;31m                                   trsf=transforms_val)}\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-cb4631c274a9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, train, trsf)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrsf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrsf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-cb4631c274a9>\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(root_dir, train)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtxt_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/dic/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'train.txt'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'val_ll.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/guolibao/cardiac/cardiac-4ch/dic/val_ll.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJJX_mmMrxw5"
      },
      "source": [
        "from __future__ import print_function\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import os.path as osp\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from skimage import io\n",
        "from skimage import segmentation as seg\n",
        "import glob\n",
        "\n",
        "\n",
        "datadir = '/home/guolibao/cardiac'\n",
        "voc_root = os.path.join(datadir, 'cardiac-4ch')\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
        "if torch.cuda.is_available():\n",
        "    device=torch.device('cuda')\n",
        "else:\n",
        "    device=torch.device('cpu')\n",
        "\n",
        "def read_images(root_dir, train):\n",
        "    txt_fname = root_dir + '/dic/' + ('train.txt' if train else 'val_ll.txt')\n",
        "    with open(txt_fname, 'r')as f:\n",
        "        images = f.read().split()\n",
        "\n",
        "    if train:\n",
        "        data_list = [os.path.join(root_dir, 'train', i) for i in images]\n",
        "\n",
        "        label_list = [os.path.join(root_dir, 'train_labels', i) for i in images]\n",
        "    else:\n",
        "        data_list = [os.path.join(root_dir, 'val', i) for i in images]\n",
        "       # print(data_list)\n",
        "        label_list = [os.path.join(root_dir, 'val_labels', i) for i in images]\n",
        "    return data_list, label_list\n",
        "\n",
        "\n",
        "\n",
        "class Cardiac(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, root_dir=voc_root, train=True, trsf=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.trsf = trsf\n",
        "        self.data_list, self.label_list = read_images(root_dir, train)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data_list[idx], self.label_list[idx]\n",
        "        image, label = Image.open(image).convert('RGB'), Image.open(label)\n",
        "        image = transforms.Resize((512, 512), interpolation=Image.BILINEAR)(image)\n",
        "        label = transforms.Resize((512, 512), interpolation=Image.BILINEAR)(label)\n",
        "        sample = {'image': image, 'label': label}\n",
        "        if self.trsf:\n",
        "            sample = self.trsf(sample)\n",
        "        return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        image = transforms.ToTensor()(image)\n",
        "        label = torch.from_numpy(np.array(label, dtype='int'))\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    def __init__(self, mean=[0., 0., 0.], std=[1., 1., 1.]):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        image = transforms.Normalize(self.mean, self.std)(image)\n",
        "        return {'image': image, 'label': label}\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    transforms_val = transforms.Compose([  # transforms.Resize(448),\n",
        "        ToTensor(),\n",
        "        Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    voc_data = {\n",
        "                'val': Cardiac(root_dir=voc_root, train=False,\n",
        "                                  trsf=transforms_val)}\n",
        "\n",
        "    mynet = torch.load('/home/guolibao/Data/unet_aspp/unetaspp_mv45.pkl')\n",
        "\n",
        "    mynet.eval()  # Set model to evaluate mode\n",
        "    mynet.cuda()\n",
        "    colormap = [[0, 0, 0], [128, 0, 0], [0, 128, 0]]\n",
        "    cm = np.array(colormap, dtype='uint8')\n",
        "    txt_fname = '/home/guolibao/cardiac/cardiac-4ch/dic/val.txt'\n",
        "    with open(txt_fname, 'r')as f:\n",
        "        images = f.read().split()\n",
        "    imgs = [os.path.join(datadir, 'cardiac/val_labels', i) for i in images]\n",
        "    for i, img in enumerate(imgs):\n",
        "        val_sample = voc_data['val'][i]\n",
        "        val_image = val_sample['image'].cuda()\n",
        "        val_label = val_sample['label']\n",
        "        val_output = mynet(val_image.unsqueeze(0))\n",
        "        val_pred = val_output.max(dim=1)[1].squeeze(0).data.cpu().numpy()\n",
        "        val_label = val_label.long().data.numpy()\n",
        "        val_image = val_image.squeeze().data.cpu().numpy().transpose((1, 2, 0))\n",
        "        val_image = val_image * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
        "        val_image *= 255\n",
        "        val_image = val_image.astype(np.uint8)\n",
        "        val_pred_tian = cm[val_pred]\n",
        "        val_pred_bin=seg.mark_boundaries(val_image,val_label,color=(128,0,0))\n",
        "        val_pred_bin = seg.mark_boundaries(val_pred_bin, val_pred, color=(0, 128, 0))\n",
        "\n",
        "        plt.imsave(osp.join('/home/guolibao/cardiac/pred_test/unetaspp_mv', img.split('/')[-1]), val_pred_tian)\n",
        "        plt.imsave(osp.join('/home/guolibao/cardiac/pred_test/unetaspp_mv_bin', img.split('/')[-1]), val_pred_bin)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}